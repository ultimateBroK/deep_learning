#!/usr/bin/env python3
"""
ğŸ¯ ENTRY POINT: CHAY PROJECT CLI
---------------------------------

Giáº£i thÃ­ch:
- File nÃ y lÃ  "cá»­a chÃ­nh" Ä‘á»ƒ cháº¡y toÃ n bá»™ project
- Cháº¡y tá»« terminal vá»›i cÃ¡c tham sá»‘
- Tá»± Ä‘á»™ng cháº¡y qua táº¥t cáº£ cÃ¡c bÆ°á»›c

CÃ¡ch dÃ¹ng:
    python main.py --epochs 20 --limit 1500
"""

import argparse
import sys
from pathlib import Path

# ThÃªm thÆ° má»¥c gá»‘c vÃ o path
sys.path.insert(0, str(Path(__file__).parent))

# LÆ°u Ã½: khÃ´ng import cÃ¡c module "náº·ng" á»Ÿ top-level Ä‘á»ƒ `python main.py --help` cháº¡y gá»n vÃ  nhanh.


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="Dá»± bÃ¡o giÃ¡ Bitcoin vá»›i BiLSTM",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥:
  python main.py --epochs 20 --limit 1500
  python main.py --timeframe 4h --window 30
  python main.py --refresh-cache
        """
    )
    
    # Data args
    parser.add_argument(
        '--symbol',
        type=str,
        default='BTC/USDT',
        help='Cáº·p giao dá»‹ch (máº·c Ä‘á»‹nh: BTC/USDT)'
    )
    parser.add_argument(
        '--timeframe',
        type=str,
        default='1d',
        choices=['1d', '4h', '1h'],
        help='Khung thá»i gian (máº·c Ä‘á»‹nh: 1d)'
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=1500,
        help='Sá»‘ náº¿n láº¥y tá»« Binance (máº·c Ä‘á»‹nh: 1500)'
    )
    parser.add_argument(
        '--refresh-cache',
        action='store_true',
        help='Táº£i láº¡i dá»¯ liá»‡u tá»« Binance (khÃ´ng dÃ¹ng cache)'
    )
    
    # Preprocessing args
    parser.add_argument(
        '--window',
        type=int,
        default=60,
        help='Sá»‘ náº¿n nhÃ¬n láº¡i (máº·c Ä‘á»‹nh: 60)'
    )
    parser.add_argument(
        '--features',
        type=str,
        nargs='+',
        default=['close'],
        help='Features sá»­ dá»¥ng (máº·c Ä‘á»‹nh: close)'
    )
    
    # Model args
    parser.add_argument(
        '--lstm-units',
        type=int,
        nargs='+',
        default=[64, 32],
        help='Sá»‘ units cho má»—i LSTM layer (máº·c Ä‘á»‹nh: 64 32)'
    )
    parser.add_argument(
        '--dropout',
        type=float,
        default=0.2,
        help='Dropout rate (máº·c Ä‘á»‹nh: 0.2)'
    )
    
    # Training args
    parser.add_argument(
        '--epochs',
        type=int,
        default=20,
        help='Sá»‘ epochs (máº·c Ä‘á»‹nh: 20)'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='Batch size (máº·c Ä‘á»‹nh: 32)'
    )
    
    # Runtime args
    parser.add_argument(
        '--intra-threads',
        type=int,
        default=12,
        help='CPU threads cho operations (máº·c Ä‘á»‹nh: 12)'
    )

    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='Cá»‘ Ä‘á»‹nh ngáº«u nhiÃªn Ä‘á»ƒ tÃ¡i láº­p káº¿t quáº£ (máº·c Ä‘á»‹nh: 42, <0 = khÃ´ng set)'
    )
    
    return parser.parse_args()


def main():
    """HÃ m chÃ­nh Ä‘á»ƒ cháº¡y project"""
    # Parse args
    args = parse_args()

    # Import cÃ¡c module "náº·ng" sau khi parse args Ä‘á»ƒ:
    # - `python main.py --help` cháº¡y nhanh vÃ  khÃ´ng in log TensorFlow
    from step1_data import fetch_binance_data
    from step2_preprocessing import prepare_data_for_lstm
    from step3_model import build_bilstm_model, print_model_summary
    from step4_training import (
        train_model,
        evaluate_model,
        print_sample_predictions,
        calculate_direction_accuracy,
    )
    from step5_visualization import plot_training_history, plot_predictions, plot_all_in_one
    from utils import (
        configure_tensorflow_runtime,
        print_tensorflow_info,
        create_results_folder,
        save_markdown_report,
        save_config,
        save_metrics,
        set_random_seed,
    )
    
    print("\n" + "="*70)
    print(" " * 15 + "Dá»° BÃO GIÃ BITCOIN Vá»šI BiLSTM")
    print("="*70)
    
    # Cáº¥u hÃ¬nh TensorFlow
    set_random_seed(args.seed, deterministic=True)
    configure_tensorflow_runtime(
        intra_op_threads=args.intra_threads,
        inter_op_threads=2,
        enable_xla=True
    )
    print_tensorflow_info()
    
    # ========================================
    # BÆ¯á»šC 1: Láº¤Y Dá»® LIá»†U
    # ========================================
    print("\n" + "="*70)
    print("BÆ¯á»šC 1: Láº¤Y Dá»® LIá»†U Tá»ª BINANCE")
    print("="*70 + "\n")
    
    df = fetch_binance_data(
        symbol=args.symbol,
        timeframe=args.timeframe,
        limit=args.limit,
        save_cache=not args.refresh_cache
    )
    
    # ========================================
    # BÆ¯á»šC 2: Xá»¬ LÃ Dá»® LIá»†U
    # ========================================
    print("\n" + "="*70)
    print("BÆ¯á»šC 2: Xá»¬ LÃ Dá»® LIá»†U")
    print("="*70 + "\n")
    
    data_dict = prepare_data_for_lstm(
        df=df,
        features=args.features,
        window_size=args.window,
        scaler_type='minmax'
    )
    
    X_train = data_dict['X_train']
    y_train = data_dict['y_train']
    X_val = data_dict['X_val']
    y_val = data_dict['y_val']
    X_test = data_dict['X_test']
    y_test = data_dict['y_test']
    scaler = data_dict['scaler']
    
    # ========================================
    # BÆ¯á»šC 3: XÃ‚Y Dá»°NG MODEL
    # ========================================
    print("\n" + "="*70)
    print("BÆ¯á»šC 3: XÃ‚Y Dá»°NG MODEL BiLSTM")
    print("="*70 + "\n")
    
    input_shape = (args.window, len(args.features))
    model = build_bilstm_model(
        input_shape=input_shape,
        lstm_units=args.lstm_units,
        dropout_rate=args.dropout,
        dense_units=[16],
        output_units=1
    )
    print_model_summary(model)
    
    # ========================================
    # BÆ¯á»šC 4: TRAINING
    # ========================================
    print("\n" + "="*70)
    print("BÆ¯á»šC 4: TRAINING MODEL")
    print("="*70 + "\n")
    
    train_result = train_model(
        model=model,
        X_train=X_train,
        y_train=y_train,
        X_val=X_val,
        y_val=y_val,
        epochs=args.epochs,
        batch_size=args.batch_size,
        early_stopping_patience=5
    )
    
    history = train_result['history']
    
    # ========================================
    # BÆ¯á»šC 5: ÄÃNH GIÃ & Váº¼ BIá»‚U Äá»’
    # ========================================
    print("\n" + "="*70)
    print("BÆ¯á»šC 5: ÄÃNH GIÃ & Váº¼ BIá»‚U Äá»’")
    print("="*70 + "\n")
    
    # ÄÃ¡nh giÃ¡ trÃªn test set
    eval_result = evaluate_model(
        model=model,
        X_test=X_test,
        y_test=y_test,
        scaler=scaler,
        return_predictions=True
    )
    
    y_true = eval_result['y_true']
    y_pred = eval_result['predictions']
    
    # In má»™t sá»‘ vÃ­ dá»¥ dá»± Ä‘oÃ¡n
    print_sample_predictions(y_true, y_pred, n_samples=10)
    
    # TÃ­nh Ä‘á»™ chÃ­nh xÃ¡c xu hÆ°á»›ng
    calculate_direction_accuracy(y_true, y_pred)
    
    # ========================================
    # LÆ¯U Káº¾T QUáº¢
    # ========================================
    print("\n" + "="*70)
    print("LÆ¯U Káº¾T QUáº¢")
    print("="*70 + "\n")
    
    # Táº¡o folder káº¿t quáº£
    results_folder = create_results_folder(run_type="main")
    print(f"\nğŸ“ Folder káº¿t quáº£: {results_folder}\n")
    
    # Váº½ vÃ  lÆ°u biá»ƒu Ä‘á»“
    timestamp_suffix = results_folder.name.replace('BiLSTM_', '')
    
    plot_history_file = results_folder / f"training_history_{timestamp_suffix}.png"
    plot_predictions_file = results_folder / f"predictions_{timestamp_suffix}.png"
    plot_all_in_one_file = results_folder / f"all_in_one_{timestamp_suffix}.png"
    
    plot_training_history(history, save_path=str(plot_history_file))
    plot_predictions(y_true, y_pred, save_path=str(plot_predictions_file))
    plot_all_in_one(history, y_true, y_pred, save_path=str(plot_all_in_one_file))
    
    # LÆ°u bÃ¡o cÃ¡o
    config_dict = {
        'symbol': args.symbol,
        'timeframe': args.timeframe,
        'limit': args.limit,
        'window_size': args.window,
        'features': args.features,
        'lstm_units': args.lstm_units,
        'dropout_rate': args.dropout,
        'epochs': args.epochs,
        'batch_size': args.batch_size,
        'intra_threads': args.intra_threads,
        'seed': args.seed,
    }
    
    plots_dict = {
        'training_history': timestamp_suffix,
        'predictions': timestamp_suffix,
        'all_in_one': timestamp_suffix
    }
    
    save_markdown_report(
        folder_path=results_folder,
        config=config_dict,
        metrics=eval_result,
        history=history.history,
        plots=plots_dict
    )
    save_config(results_folder, config_dict)
    save_metrics(results_folder, eval_result)
    
    # ========================================
    # HOÃ€N THÃ€NH
    # ========================================
    print("\n" + "="*70)
    print("âœ… HOÃ€N THÃ€NH!")
    print("="*70)
    print(f"ğŸ“Š BÃ¡o cÃ¡o: {results_folder / f'results_BiLSTM_{timestamp_suffix}.md'}")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
