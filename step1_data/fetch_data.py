"""
BÆ¯á»šC 1: Äá»ŒC Dá»® LIá»†U Tá»ª FILE CSV (LOCAL)
---------------------------------

Giáº£i thÃ­ch báº±ng vÃ­ dá»¥ Ä‘á»i sá»‘ng:
- Giá»‘ng nhÆ° báº¡n Ä‘Ã£ táº£i sáºµn má»™t file lá»‹ch sá»­ giÃ¡ Bitcoin vá» mÃ¡y
- Thay vÃ¬ gá»i API (CCXT/Binance), ta Ä‘á»c trá»±c tiáº¿p file CSV
- Sau Ä‘Ã³ chuáº©n hoÃ¡ cá»™t Ä‘á»ƒ pipeline phÃ­a sau dÃ¹ng thá»‘ng nháº¥t
"""

from datetime import datetime
from pathlib import Path
import pandas as pd
import re


def _project_root() -> Path:
    # step1_data/ náº±m ngay dÆ°á»›i root project
    return Path(__file__).resolve().parents[1]


def _default_data_path(timeframe: str) -> Path:
    """
    Chá»n file data máº·c Ä‘á»‹nh theo timeframe.
    - 1d  -> data/btc_1d_data_2018_to_2025.csv
    - 4h  -> data/btc_4h_data_2018_to_2025.csv
    """
    data_dir = _project_root() / "data"
    tf = (timeframe or "1d").lower()
    if tf == "4h":
        return data_dir / "btc_4h_data_2018_to_2025.csv"
    return data_dir / "btc_1d_data_2018_to_2025.csv"


def _infer_timeframe_from_filename(path: Path) -> str | None:
    name = path.name.lower()
    if re.search(r"(?:^|_)4h(?:_|\\.)", name) or "4h" in name:
        return "4h"
    if re.search(r"(?:^|_)1d(?:_|\\.)", name) or "1d" in name:
        return "1d"
    return None


def _normalize_binance_export_csv(df_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Chuáº©n hoÃ¡ CSV kiá»ƒu "Binance export" vá» schema thá»‘ng nháº¥t:
    datetime/open/high/low/close/volume
    """
    if df_raw is None or len(df_raw) == 0:
        return pd.DataFrame(columns=["datetime", "open", "high", "low", "close", "volume"])

    df = df_raw.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # Map cá»™t (CSV cá»§a báº¡n cÃ³ format: Open time, Open, High, Low, Close, Volume, ...)
    required = ["Open time", "Open", "High", "Low", "Close", "Volume"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(
            f"CSV thiáº¿u cá»™t báº¯t buá»™c: {missing}. "
            f"Hiá»‡n cÃ³: {list(df.columns)}"
        )

    out = pd.DataFrame()
    out["datetime"] = pd.to_datetime(df["Open time"], errors="coerce", utc=True)
    # ÄÆ°a vá» naive datetime (dá»… in/report). Pipeline khÃ´ng phá»¥ thuá»™c timezone.
    out["datetime"] = out["datetime"].dt.tz_convert(None)

    for col_in, col_out in [
        ("Open", "open"),
        ("High", "high"),
        ("Low", "low"),
        ("Close", "close"),
        ("Volume", "volume"),
    ]:
        out[col_out] = pd.to_numeric(df[col_in], errors="coerce")

    out = out.dropna(subset=["datetime", "close"]).sort_values("datetime").reset_index(drop=True)
    return out[["datetime", "open", "high", "low", "close", "volume"]]


def fetch_binance_data(
    data_path: str | None = None,
    symbol: str = "BTC/USDT",
    timeframe: str = "1d",
    limit: int = 1500,
    save_cache: bool = True,
    cache_dir: str = None
) -> pd.DataFrame:
    """
    Äá»c dá»¯ liá»‡u giÃ¡ tá»« file CSV local (máº·c Ä‘á»‹nh: `data/btc_1d_data_2018_to_2025.csv`)
    
    Args:
        data_path: ÄÆ°á»ng dáº«n CSV. Náº¿u None -> chá»n máº·c Ä‘á»‹nh theo timeframe.
        symbol: (DEPRECATED) giá»¯ láº¡i Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch notebook cÅ©, khÃ´ng cÃ²n dÃ¹ng Ä‘á»ƒ fetch API.
        timeframe: DÃ¹ng Ä‘á»ƒ chá»n file máº·c Ä‘á»‹nh khi data_path=None (1d/4h).
        limit: Láº¥y N dÃ²ng cuá»‘i (None hoáº·c <=0 -> láº¥y toÃ n bá»™).
        save_cache: CÃ³ lÆ°u cache (CSV Ä‘Ã£ chuáº©n hoÃ¡) Ä‘á»ƒ láº§n sau Ä‘á»c nhanh hÆ¡n khÃ´ng.
        cache_dir: ThÆ° má»¥c cache (máº·c Ä‘á»‹nh: step1_data/cache)
    
    Returns:
        DataFrame vá»›i cÃ¡c cá»™t: open, high, low, close, volume, datetime
    """
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c cache
    if cache_dir is None:
        cache_dir = Path(__file__).parent / "cache"
    else:
        cache_dir = Path(cache_dir)
    
    cache_dir.mkdir(parents=True, exist_ok=True)

    # XÃ¡c Ä‘á»‹nh file dá»¯ liá»‡u
    if data_path is None:
        data_file = _default_data_path(timeframe)
    else:
        data_file = Path(data_path)

    if not data_file.exists():
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file data: {data_file}")

    inferred_tf = _infer_timeframe_from_filename(data_file) or (timeframe or "1d")

    # TÃªn file cache dá»±a trÃªn file data + timeframe + limit
    stem = data_file.stem
    lim = int(limit) if isinstance(limit, int) else limit
    cache_filename = f"{stem}_{inferred_tf}_{lim if lim and lim > 0 else 'all'}.normalized.csv"
    cache_path = cache_dir / cache_filename
    
    # Náº¿u cache Ä‘Ã£ tá»“n táº¡i vÃ  save_cache=True, Ä‘á»c tá»« cache
    if save_cache and cache_path.exists():
        print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« cache: {cache_path}")
        df = pd.read_csv(cache_path)
        df['datetime'] = pd.to_datetime(df['datetime'])
        return df

    print(f"ğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u tá»« CSV: {data_file}")
    print(f"ğŸ•’ Timeframe (tá»« tÃªn file): {inferred_tf}")
    if symbol and symbol != "BTC/USDT":
        # Chá»‰ cáº£nh bÃ¡o nháº¹ Ä‘á»ƒ khÃ´ng lÃ m há»ng notebook cÅ©
        print(f"â„¹ï¸  (Bá» qua) symbol={symbol} â€” hiá»‡n Ä‘ang dÃ¹ng dá»¯ liá»‡u tá»« file CSV local.")

    raw = pd.read_csv(data_file)
    df = _normalize_binance_export_csv(raw)

    if isinstance(limit, int) and limit > 0 and len(df) > limit:
        df = df.tail(limit).reset_index(drop=True)
    
    # LÆ°u vÃ o cache náº¿u save_cache=True
    if save_cache:
        df.to_csv(cache_path, index=False)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u cache vÃ o: {cache_path}")
    
    print(f"âœ… ÄÃ£ táº£i {len(df)} dÃ²ng dá»¯ liá»‡u")
    print(f"   Thá»i gian: {df['datetime'].iloc[0]} Ä‘áº¿n {df['datetime'].iloc[-1]}")
    
    return df


def clear_cache(cache_dir: str = None, older_than_days: int = None) -> int:
    """
    XÃ³a cache dá»¯ liá»‡u
    
    Args:
        cache_dir: ThÆ° má»¥c cache
        older_than_days: Chá»‰ xÃ³a file cÅ© hÆ¡n sá»‘ ngÃ y nÃ y (None = xÃ³a táº¥t cáº£)
    
    Returns:
        Sá»‘ file Ä‘Ã£ xÃ³a
    """
    if cache_dir is None:
        cache_dir = Path(__file__).parent / "cache"
    else:
        cache_dir = Path(cache_dir)
    
    if not cache_dir.exists():
        return 0
    
    deleted_count = 0
    current_time = datetime.now().timestamp()
    
    for file_path in cache_dir.glob("*.csv"):
        if older_than_days is None:
            # XÃ³a táº¥t cáº£
            file_path.unlink()
            deleted_count += 1
        else:
            # Chá»‰ xÃ³a file cÅ© hÆ¡n sá»‘ ngÃ y quy Ä‘á»‹nh
            file_age_days = (current_time - file_path.stat().st_mtime) / 86400
            if file_age_days > older_than_days:
                file_path.unlink()
                deleted_count += 1
    
    if deleted_count > 0:
        print(f"ğŸ—‘ï¸  ÄÃ£ xÃ³a {deleted_count} file cache")
    else:
        print("âœ… KhÃ´ng cÃ³ file cache nÃ o Ä‘á»ƒ xÃ³a")
    
    return deleted_count


if __name__ == "__main__":
    # Test function
    df = fetch_binance_data(timeframe="1d", limit=100)
    print(df.head())
