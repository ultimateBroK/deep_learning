"""
BÆ¯á»šC 1: Äá»ŒC Dá»® LIá»†U Tá»ª FILE CSV (LOCAL)
---------------------------------

Giáº£i thÃ­ch báº±ng vÃ­ dá»¥ Ä‘á»i sá»‘ng:
- Giá»‘ng nhÆ° báº¡n Ä‘Ã£ táº£i sáºµn má»™t file lá»‹ch sá»­ giÃ¡ Bitcoin vá» mÃ¡y
- Thay vÃ¬ gá»i API (CCXT/Binance), ta Ä‘á»c trá»±c tiáº¿p file CSV
- Sau Ä‘Ã³ chuáº©n hoÃ¡ cá»™t Ä‘á»ƒ pipeline phÃ­a sau dÃ¹ng thá»‘ng nháº¥t
"""

from datetime import datetime
from pathlib import Path
import polars as pl


def _project_root() -> Path:
    # step1_data/ náº±m ngay dÆ°á»›i root project
    return Path(__file__).resolve().parents[1]


def _default_data_path(timeframe: str) -> Path:
    """
    Chá»n file data máº·c Ä‘á»‹nh theo timeframe.
    - 1d  -> data/btc_1d_data_2018_to_2025.csv
    - 4h  -> data/btc_4h_data_2018_to_2025.csv
    """
    data_dir = _project_root() / "data"
    tf = (timeframe or "1d").lower()
    if tf == "4h":
        return data_dir / "btc_4h_data_2018_to_2025.csv"
    return data_dir / "btc_1d_data_2018_to_2025.csv"


def _infer_timeframe_from_filename(path: Path) -> str | None:
    name = path.name.lower()
    if "4h" in name:
        return "4h"
    if "1d" in name:
        return "1d"
    return None


def _normalize_binance_export_csv(df_raw: pl.DataFrame) -> pl.DataFrame:
    """
    Chuáº©n hoÃ¡ CSV kiá»ƒu "Binance export" vá» schema thá»‘ng nháº¥t:
    datetime/open/high/low/close/volume
    """
    if df_raw is None or len(df_raw) == 0:
        return pl.DataFrame(
            schema=["datetime", "open", "high", "low", "close", "volume"]
        )

    # Map cá»™t (CSV cá»§a báº¡n cÃ³ format: Open time, Open, High, Low, Close, Volume, ...)
    required = ["Open time", "Open", "High", "Low", "Close", "Volume"]
    columns = df_raw.columns
    missing = [c for c in required if c not in columns]
    if missing:
        raise ValueError(
            f"CSV thiáº¿u cá»™t báº¯t buá»™c: {missing}. "
            f"Hiá»‡n cÃ³: {list(columns)}"
        )

    # Táº¡o DataFrame má»›i vá»›i schema chuáº©n
    # Strip khoáº£ng tráº¯ng á»Ÿ cá»™t Open time trÆ°á»›c khi parse
    df_raw = df_raw.with_columns([
        pl.col("Open time").str.strip_chars()
    ])

    # Kiá»ƒm tra xem cá»™t Open time cÃ³ chá»©a " UTC" khÃ´ng báº±ng cÃ¡ch láº¥y 1 máº«u Ä‘áº§u tiÃªn
    first_sample = df_raw.select(pl.col("Open time")).row(0)[0]
    has_utc = " UTC" in first_sample

    # Parse datetime theo format phÃ¹ há»£p
    if has_utc:
        df_parsed = df_raw.with_columns([
            pl.col("Open time").str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S%.f UTC", strict=False)
        ])
    else:
        df_parsed = df_raw.with_columns([
            pl.col("Open time").str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S%.f", strict=False)
        ])

    out = (
        df_parsed
        .rename({
            "Open time": "datetime",
            "Open": "open",
            "High": "high",
            "Low": "low",
            "Close": "close",
            "Volume": "volume"
        })
        .with_columns([
            pl.col("datetime").dt.replace_time_zone(None),
            pl.col("open").cast(pl.Float64),
            pl.col("high").cast(pl.Float64),
            pl.col("low").cast(pl.Float64),
            pl.col("close").cast(pl.Float64),
            pl.col("volume").cast(pl.Float64)
        ])
        .filter(pl.col("datetime").is_not_null() & pl.col("close").is_not_null())
        .sort("datetime")
    )

    return out.select(["datetime", "open", "high", "low", "close", "volume"])


def fetch_binance_data(
    data_path: str | None = None,
    symbol: str = "BTC/USDT",
    timeframe: str = "1d",
    limit: int = 1500,
    save_cache: bool = True,
    cache_dir: str = None
) -> pl.DataFrame:
    """
    Äá»c dá»¯ liá»‡u giÃ¡ tá»« file CSV local (máº·c Ä‘á»‹nh: `data/btc_1d_data_2018_to_2025.csv`)
    
    Args:
        data_path: ÄÆ°á»ng dáº«n CSV. Náº¿u None -> chá»n máº·c Ä‘á»‹nh theo timeframe.
        symbol: (DEPRECATED) giá»¯ láº¡i Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch notebook cÅ©, khÃ´ng cÃ²n dÃ¹ng Ä‘á»ƒ fetch API.
        timeframe: DÃ¹ng Ä‘á»ƒ chá»n file máº·c Ä‘á»‹nh khi data_path=None (1d/4h).
        limit: Láº¥y N dÃ²ng cuá»‘i (None hoáº·c <=0 -> láº¥y toÃ n bá»™).
        save_cache: CÃ³ lÆ°u cache (CSV Ä‘Ã£ chuáº©n hoÃ¡) Ä‘á»ƒ láº§n sau Ä‘á»c nhanh hÆ¡n khÃ´ng.
        cache_dir: ThÆ° má»¥c cache (máº·c Ä‘á»‹nh: step1_data/cache)
    
    Returns:
        DataFrame vá»›i cÃ¡c cá»™t: open, high, low, close, volume, datetime
    """
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c cache
    if cache_dir is None:
        cache_dir = Path(__file__).parent / "cache"
    else:
        cache_dir = Path(cache_dir)
    
    cache_dir.mkdir(parents=True, exist_ok=True)

    # XÃ¡c Ä‘á»‹nh file dá»¯ liá»‡u
    if data_path is None:
        data_file = _default_data_path(timeframe)
    else:
        data_file = Path(data_path)

    if not data_file.exists():
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file data: {data_file}")

    inferred_tf = _infer_timeframe_from_filename(data_file) or (timeframe or "1d")

    # TÃªn file cache dá»±a trÃªn file data + timeframe + limit
    stem = data_file.stem
    lim = int(limit) if isinstance(limit, int) else limit
    cache_filename = f"{stem}_{inferred_tf}_{lim if lim and lim > 0 else 'all'}.normalized.csv"
    cache_path = cache_dir / cache_filename
    
    # Náº¿u cache Ä‘Ã£ tá»“n táº¡i vÃ  save_cache=True, Ä‘á»c tá»« cache
    if save_cache and cache_path.exists():
        print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« cache: {cache_path}")
        df = pl.read_csv(cache_path, try_parse_dates=True)
        return df

    print(f"ğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u tá»« CSV: {data_file}")
    print(f"ğŸ•’ Timeframe (tá»« tÃªn file): {inferred_tf}")
    if symbol and symbol != "BTC/USDT":
        # Chá»‰ cáº£nh bÃ¡o nháº¹ Ä‘á»ƒ khÃ´ng lÃ m há»ng notebook cÅ©
        print(f"â„¹ï¸  (Bá» qua) symbol={symbol} â€” hiá»‡n Ä‘ang dÃ¹ng dá»¯ liá»‡u tá»« file CSV local.")

    raw = pl.read_csv(data_file)
    df = _normalize_binance_export_csv(raw)

    if len(df) == 0:
        raise ValueError(
            f"DataFrame rá»—ng sau khi normalize. CÃ³ thá»ƒ do format datetime khÃ´ng há»£p lá»‡ "
            f"hoáº·c táº¥t cáº£ dÃ²ng bá»‹ filter. Vui lÃ²ng kiá»ƒm tra file: {data_file}"
        )

    if isinstance(limit, int) and limit > 0 and len(df) > limit:
        df = df.tail(limit)

    # LÆ°u vÃ o cache náº¿u save_cache=True
    if save_cache:
        df.write_csv(cache_path)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u cache vÃ o: {cache_path}")

    print(f"âœ… ÄÃ£ táº£i {len(df)} dÃ²ng dá»¯ liá»‡u")
    print(f"   Thá»i gian: {df.select('datetime').row(0)[0]} Ä‘áº¿n {df.select('datetime').row(-1)[0]}")
    
    return df


def clear_cache(cache_dir: str = None, older_than_days: int = None) -> int:
    """
    XÃ³a cache dá»¯ liá»‡u
    
    Args:
        cache_dir: ThÆ° má»¥c cache
        older_than_days: Chá»‰ xÃ³a file cÅ© hÆ¡n sá»‘ ngÃ y nÃ y (None = xÃ³a táº¥t cáº£)
    
    Returns:
        Sá»‘ file Ä‘Ã£ xÃ³a
    """
    if cache_dir is None:
        cache_dir = Path(__file__).parent / "cache"
    else:
        cache_dir = Path(cache_dir)
    
    if not cache_dir.exists():
        return 0
    
    deleted_count = 0
    current_time = datetime.now().timestamp()
    
    for file_path in cache_dir.glob("*.csv"):
        if older_than_days is None:
            # XÃ³a táº¥t cáº£
            file_path.unlink()
            deleted_count += 1
        else:
            # Chá»‰ xÃ³a file cÅ© hÆ¡n sá»‘ ngÃ y quy Ä‘á»‹nh
            file_age_days = (current_time - file_path.stat().st_mtime) / 86400
            if file_age_days > older_than_days:
                file_path.unlink()
                deleted_count += 1
    
    if deleted_count > 0:
        print(f"ğŸ—‘ï¸  ÄÃ£ xÃ³a {deleted_count} file cache")
    else:
        print("âœ… KhÃ´ng cÃ³ file cache nÃ o Ä‘á»ƒ xÃ³a")
    
    return deleted_count


if __name__ == "__main__":
    # Test function
    df = fetch_binance_data(timeframe="1d", limit=100)
    print(df.head())
