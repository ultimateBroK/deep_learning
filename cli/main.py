"""
üéØ ENTRY POINT - CLI MAIN
---------------------------

Gi·∫£i th√≠ch b·∫±ng v√≠ d·ª• ƒë·ªùi s·ªëng:
- Gi·ªëng nh∆∞ "c·ª≠a ch√≠nh" v√†o nh√†
- User m·ªü c·ª≠a ‚Üí CLI ch√†o ƒë√≥n ‚Üí G·ªçi pipeline

KISS (Keep It Simple, Stupid):
- Ch·ªâ parse arguments
- Ch·ªâ g·ªçi pipeline
- Kh√¥ng ch·ª©a business logic

Usage:
    python -m cli.main --epochs 20 --limit 1500
    python -m cli.main --help
"""

import argparse
import os
import sys
import warnings
from pathlib import Path

# Suppress warnings TR∆Ø·ªöC khi import b·∫•t k·ª≥ th·ª© g√¨
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Ch·ªâ hi·ªÉn th·ªã ERROR (0=all, 1=no INFO, 2=no WARNING, 3=no ERROR)
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # T·∫Øt oneDNN warnings

# Suppress Python warnings
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', message='.*np.object.*')
warnings.filterwarnings('ignore', message='.*oneDNN.*')
warnings.filterwarnings('ignore', message='.*CUDA.*')
warnings.filterwarnings('ignore', message='.*Could not find cuda.*')
warnings.filterwarnings('ignore', message='.*cuda drivers.*')
warnings.filterwarnings('ignore', message='.*GPU will not be used.*')

# Th√™m src v√†o path ƒë·ªÉ import ƒë∆∞·ª£c
sys.path.insert(0, str(Path(__file__).parent.parent))

# Import v√† suppress TensorFlow logger ngay l·∫≠p t·ª©c
try:
    import tensorflow as tf
    tf.get_logger().setLevel('ERROR')
    # Suppress stderr output t·ª´ TensorFlow
    import logging
    logging.getLogger('tensorflow').setLevel(logging.ERROR)
except ImportError:
    pass  # TensorFlow ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t

from src import Config, run_pipeline, get_default_config, get_fast_config, get_1h_light_config, get_4h_balanced_config, get_scalping_ultra_fast_config, get_scalping_fast_config, get_intraday_light_config, get_intraday_balanced_config, get_swing_fast_config, get_swing_balanced_config, get_long_term_config, get_production_config   # noqa: E402
from src.core.data import _infer_timeframe_from_filename   # noqa: E402


def parse_args():
    """
    Parse command line arguments

    Gi·∫£i th√≠ch: Gi·ªëng nh∆∞ "l·∫Øng nghe y√™u c·∫ßu" t·ª´ user
    """
    parser = argparse.ArgumentParser(
        description="D·ª± b√°o gi√° Bitcoin v·ªõi BiLSTM",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª•:
  python -m cli.main --epochs 20 --limit 1500
  python -m cli.main --timeframe 4h --window 30
  python -m cli.main --refresh-cache
        """
    )

    # ==================== DATA ARGS ====================
    data_group = parser.add_argument_group("üì• Data", "D·ªØ li·ªáu ƒë·∫ßu v√†o")

    data_group.add_argument(
        '--data-path',
        type=str,
        default=None,
        help='ƒê∆∞·ªùng d·∫´n file CSV (n·∫øu b·ªè tr·ªëng s·∫Ω ch·ªçn theo --timeframe)'
    )
    data_group.add_argument(
        '--timeframe',
        type=str,
        default=None,
        choices=['1d', '4h', '1h', '15m'],
        help='Timeframe (m·∫∑c ƒë·ªãnh: 1d)'
    )
    data_group.add_argument(
        '--limit',
        type=int,
        default=None,
        help='L·∫•y N d√≤ng cu·ªëi trong file CSV (m·∫∑c ƒë·ªãnh: 1500, <=0 = l·∫•y t·∫•t c·∫£)'
    )
    data_group.add_argument(
        '--refresh-cache',
        action='store_true',
        help='ƒê·ªçc l·∫°i t·ª´ CSV g·ªëc (b·ªè qua cache ƒë√£ chu·∫©n ho√°)'
    )
    data_group.add_argument(
        '--features',
        type=str,
        nargs='+',
        default=None,
        help='Features s·ª≠ d·ª•ng (m·∫∑c ƒë·ªãnh: close)'
    )

    # ==================== PREPROCESSING ARGS ====================
    prep_group = parser.add_argument_group("üîß Preprocessing", "X·ª≠ l√Ω d·ªØ li·ªáu")

    prep_group.add_argument(
        '--window',
        type=int,
        default=None,
        help='S·ªë n·∫øn nh√¨n l·∫°i (m·∫∑c ƒë·ªãnh: 60)'
    )
    prep_group.add_argument(
        '--scaler-type',
        type=str,
        default=None,
        choices=['minmax', 'standard'],
        help='Lo·∫°i scaler (m·∫∑c ƒë·ªãnh: minmax)'
    )

    # ==================== MODEL ARGS ====================
    model_group = parser.add_argument_group("üß† Model", "C·∫•u h√¨nh model")

    model_group.add_argument(
        '--lstm-units',
        type=int,
        nargs='+',
        default=None,
        help='S·ªë units cho m·ªói LSTM layer (m·∫∑c ƒë·ªãnh: 64 32)'
    )
    model_group.add_argument(
        '--dropout',
        type=float,
        default=None,
        help='Dropout rate (m·∫∑c ƒë·ªãnh: 0.2)'
    )

    # ==================== TRAINING ARGS ====================
    train_group = parser.add_argument_group("üèãÔ∏è Training", "Hu·∫•n luy·ªán model")

    train_group.add_argument(
        '--epochs',
        type=int,
        default=None,
        help='S·ªë epochs (m·∫∑c ƒë·ªãnh: 20)'
    )
    train_group.add_argument(
        '--batch-size',
        type=int,
        default=None,
        help='Batch size (m·∫∑c ƒë·ªãnh: 32)'
    )
    train_group.add_argument(
        '--learning-rate',
        type=float,
        default=None,
        help='Learning rate (m·∫∑c ƒë·ªãnh: 0.001)'
    )
    train_group.add_argument(
        '--early-stopping-patience',
        type=int,
        default=None,
        help='S·ªë epochs ch·ªù tr∆∞·ªõc khi d·ª´ng (m·∫∑c ƒë·ªãnh: 5)'
    )

    # ==================== RUNTIME ARGS ====================
    runtime_group = parser.add_argument_group("‚ö° Runtime", "C·∫•u h√¨nh runtime")

    runtime_group.add_argument(
        '--intra-threads',
        type=int,
        default=None,
        help='CPU threads cho operations trong c√πng op (m·∫∑c ƒë·ªãnh: 12)'
    )
    runtime_group.add_argument(
        '--inter-threads',
        type=int,
        default=None,
        help='CPU threads cho operations kh√°c nhau (m·∫∑c ƒë·ªãnh: 2)'
    )
    runtime_group.add_argument(
        '--seed',
        type=int,
        default=None,
        help='C·ªë ƒë·ªãnh ng·∫´u nhi√™n ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£ (m·∫∑c ƒë·ªãnh: 42, <0 = kh√¥ng set)'
    )

    # ==================== PRESET ====================
    preset_group = parser.add_argument_group("üì¶ Preset", "C·∫•u h√¨nh c√≥ s·∫µn")

    preset_group.add_argument(
        '--preset',
        type=str,
        choices=['default', 'fast', '1h-light', '4h-balanced', 'scalping-ultra-fast', 'scalping-fast', 'intraday-light', 'intraday-balanced', 'swing-fast', 'swing-balanced', 'long-term', 'production'],
        default='default',
        help='Preset config (m·∫∑c ƒë·ªãnh: default)'
    )

    return parser.parse_args()


def main():
    """
    Main entry point

    Gi·∫£i th√≠ch: Gi·ªëng nh∆∞ "nh√¢n vi√™n l·ªÖ t√¢n" - ti·∫øp nh·∫≠n, chuy·ªÉn ti·∫øp
    """
    # Parse args
    args = parse_args()

    # Ch·ªçn preset
    preset_map = {
        'default': get_default_config,
        'fast': get_fast_config,
        '1h-light': get_1h_light_config,
        '4h-balanced': get_4h_balanced_config,
        'scalping-ultra-fast': get_scalping_ultra_fast_config,
        'scalping-fast': get_scalping_fast_config,
        'intraday-light': get_intraday_light_config,
        'intraday-balanced': get_intraday_balanced_config,
        'swing-fast': get_swing_fast_config,
        'swing-balanced': get_swing_balanced_config,
        'long-term': get_long_term_config,
        'production': get_production_config,
    }

    config = preset_map[args.preset]()

    # Override config v·ªõi CLI args (ch·ªâ khi user truy·ªÅn v√†o)
    if args.data_path is not None:
        config.data.data_path = args.data_path
        # Infer timeframe t·ª´ filename n·∫øu user kh√¥ng ch·ªâ ƒë·ªãnh --timeframe
        if args.timeframe is None:
            inferred_tf = _infer_timeframe_from_filename(Path(args.data_path))
            if inferred_tf:
                config.data.timeframe = inferred_tf

    if args.timeframe is not None:
        config.data.timeframe = args.timeframe
    if args.limit is not None:
        config.data.limit = args.limit
    if args.refresh_cache:
        config.data.refresh_cache = args.refresh_cache
    if args.features is not None:
        config.data.features = args.features
    if args.window is not None:
        config.preprocessing.window_size = args.window
    if args.scaler_type is not None:
        config.preprocessing.scaler_type = args.scaler_type
    if args.lstm_units is not None:
        config.model.lstm_units = args.lstm_units
    if args.dropout is not None:
        config.model.dropout_rate = args.dropout
    if args.epochs is not None:
        config.training.epochs = args.epochs
    if args.batch_size is not None:
        config.training.batch_size = args.batch_size
    if args.learning_rate is not None:
        config.training.learning_rate = args.learning_rate
    if args.early_stopping_patience is not None:
        config.training.early_stopping_patience = args.early_stopping_patience
    if args.intra_threads is not None:
        config.runtime.intra_op_threads = args.intra_threads
    if args.inter_threads is not None:
        config.runtime.inter_op_threads = args.inter_threads
    if args.seed is not None:
        config.runtime.seed = args.seed

    # In header
    print("\n" + "=" * 70)
    print(" " * 15 + "D·ª∞ B√ÅO GI√Å BITCOIN V·ªöI BiLSTM")
    print("=" * 70)
    print(f"üì¶ Preset: {args.preset}")
    print("=" * 70)

    # In config summary
    print(config.summary())

    # Ch·∫°y pipeline
    run_pipeline(config, run_type="cli")


if __name__ == "__main__":
    main()
