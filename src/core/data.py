"""
ğŸ“¥ DATA MODULE - Äá»ŒC Dá»® LIá»†U
--------------------------------

Giáº£i thÃ­ch báº±ng vÃ­ dá»¥ Ä‘á»i sá»‘ng:
- Giá»‘ng nhÆ° "nhÃ¢n viÃªn kho" - chá»‹u trÃ¡ch nhiá»‡m láº¥y dá»¯ liá»‡u
- Dá»¯ liá»‡u cÃ³ sáºµn trong file CSV, khÃ´ng cáº§n gá»i API
- Chuáº©n hoÃ¡ Ä‘á»ƒ cÃ¡c bá»™ pháº­n khÃ¡c dá»… sá»­ dá»¥ng

TrÃ¡ch nhiá»‡m (SoC - Separation of Concerns):
- Äá»c file CSV
- Chuáº©n hoÃ¡ format
- Cache Ä‘á»ƒ láº§n sau Ä‘á»c nhanh
"""

from datetime import datetime
from pathlib import Path
import polars as pl
from typing import Optional


def _infer_timeframe_from_filename(path: Path) -> Optional[str]:
    """
    Infer timeframe tá»« tÃªn file
    VÃ­ dá»¥: btc_4h_data_2018_to_2025.csv â†’ 4h
    """
    name = path.name.lower()
    if "4h" in name:
        return "4h"
    if "1d" in name:
        return "1d"
    return None


def _normalize_binance_export_csv(df_raw: pl.DataFrame) -> pl.DataFrame:
    """
    Chuáº©n hoÃ¡ CSV kiá»ƒu "Binance export" vá» schema thá»‘ng nháº¥t:
    datetime/open/high/low/close/volume

    Giáº£i thÃ­ch: Giá»‘ng nhÆ° "Ä‘Ã³ng gÃ³i" - Ä‘Æ°a táº¥t cáº£ vá» cÃ¹ng format
    """
    if df_raw is None or len(df_raw) == 0:
        return pl.DataFrame(
            schema=["datetime", "open", "high", "low", "close", "volume"]
        )

    # Kiá»ƒm tra cá»™t báº¯t buá»™c
    required = ["Open time", "Open", "High", "Low", "Close", "Volume"]
    columns = df_raw.columns
    missing = [c for c in required if c not in columns]
    if missing:
        raise ValueError(
            f"CSV thiáº¿u cá»™t báº¯t buá»™c: {missing}. "
            f"Hiá»‡n cÃ³: {list(columns)}"
        )

    # Strip khoáº£ng tráº¯ng vÃ  parse datetime
    df_raw = df_raw.with_columns([
        pl.col("Open time").str.strip_chars()
    ])

    first_sample = df_raw.select(pl.col("Open time")).row(0)[0]
    has_utc = " UTC" in first_sample

    if has_utc:
        df_parsed = df_raw.with_columns([
            pl.col("Open time").str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S%.f UTC", strict=False)
        ])
    else:
        df_parsed = df_raw.with_columns([
            pl.col("Open time").str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S%.f", strict=False)
        ])

    # Chuáº©n hoÃ¡ cá»™t
    out = (
        df_parsed
        .rename({
            "Open time": "datetime",
            "Open": "open",
            "High": "high",
            "Low": "low",
            "Close": "close",
            "Volume": "volume"
        })
        .with_columns([
            pl.col("datetime").dt.replace_time_zone(None),
            pl.col("open").cast(pl.Float64),
            pl.col("high").cast(pl.Float64),
            pl.col("low").cast(pl.Float64),
            pl.col("close").cast(pl.Float64),
            pl.col("volume").cast(pl.Float64)
        ])
        .filter(pl.col("datetime").is_not_null() & pl.col("close").is_not_null())
        .sort("datetime")
    )

    return out.select(["datetime", "open", "high", "low", "close", "volume"])


def fetch_binance_data(
    data_path: Optional[str] = None,
    data_dir: Optional[Path] = None,
    timeframe: str = "1d",
    limit: int = 1500,
    save_cache: bool = True,
    cache_dir: Optional[Path] = None
) -> pl.DataFrame:
    """
    Äá»c dá»¯ liá»‡u giÃ¡ tá»« file CSV local

    Args:
        data_path: ÄÆ°á»ng dáº«n CSV. Náº¿u None â†’ chá»n theo timeframe
        data_dir: ThÆ° má»¥c chá»©a file data (máº·c Ä‘á»‹nh: project/data/)
        timeframe: Timeframe Ä‘á»ƒ chá»n file (1d/4h)
        limit: Láº¥y N dÃ²ng cuá»‘i (<=0 â†’ láº¥y táº¥t cáº£)
        save_cache: LÆ°u cache Ä‘á»ƒ láº§n sau Ä‘á»c nhanh hÆ¡n
        cache_dir: ThÆ° má»¥c cache

    Returns:
        DataFrame vá»›i cÃ¡c cá»™t: datetime, open, high, low, close, volume
    """
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c data vÃ  cache
    from ..config import Paths

    if data_dir is None:
        data_dir = Paths().data_dir
    else:
        data_dir = Path(data_dir)

    if cache_dir is None:
        cache_dir = Paths().cache_dir
    else:
        cache_dir = Path(cache_dir)

    cache_dir.mkdir(parents=True, exist_ok=True)

    # XÃ¡c Ä‘á»‹nh file dá»¯ liá»‡u
    if data_path is None:
        tf = (timeframe or "1d").lower()
        if tf == "4h":
            data_file = data_dir / "btc_4h_data_2018_to_2025.csv"
        else:
            data_file = data_dir / "btc_1d_data_2018_to_2025.csv"
    else:
        data_file = Path(data_path)

    if not data_file.exists():
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file data: {data_file}")

    inferred_tf = _infer_timeframe_from_filename(data_file) or (timeframe or "1d")

    # TÃªn file cache
    stem = data_file.stem
    lim = int(limit) if isinstance(limit, int) else limit
    cache_filename = f"{stem}_{inferred_tf}_{lim if lim and lim > 0 else 'all'}.normalized.csv"
    cache_path = cache_dir / cache_filename

    # Äá»c tá»« cache náº¿u cÃ³
    if save_cache and cache_path.exists():
        print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« cache: {cache_path}")
        df = pl.read_csv(cache_path, try_parse_dates=True)
        return df

    print(f"ğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u tá»« CSV: {data_file}")
    print(f"ğŸ•’ Timeframe (tá»« tÃªn file): {inferred_tf}")

    raw = pl.read_csv(data_file)
    df = _normalize_binance_export_csv(raw)

    if len(df) == 0:
        raise ValueError(
            f"DataFrame rá»—ng sau khi normalize. "
            f"Vui lÃ²ng kiá»ƒm tra file: {data_file}"
        )

    if isinstance(limit, int) and limit > 0 and len(df) > limit:
        df = df.tail(limit)

    # LÆ°u cache
    if save_cache:
        df.write_csv(cache_path)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u cache vÃ o: {cache_path}")

    print(f"âœ… ÄÃ£ táº£i {len(df)} dÃ²ng dá»¯ liá»‡u")
    try:
        print(f"   Thá»i gian: {df.select('datetime').row(0)[0]} Ä‘áº¿n {df.select('datetime').row(-1)[0]}")
    except Exception:
        pass

    return df


def clear_cache(cache_dir: Optional[Path] = None, older_than_days: Optional[int] = None) -> int:
    """
    XÃ³a cache dá»¯ liá»‡u

    Args:
        cache_dir: ThÆ° má»¥c cache
        older_than_days: Chá»‰ xÃ³a file cÅ© hÆ¡n sá»‘ ngÃ y nÃ y (None = xÃ³a táº¥t cáº£)

    Returns:
        Sá»‘ file Ä‘Ã£ xÃ³a
    """
    from ..config import Paths

    if cache_dir is None:
        cache_dir = Paths().cache_dir
    else:
        cache_dir = Path(cache_dir)

    if not cache_dir.exists():
        return 0

    deleted_count = 0
    current_time = datetime.now().timestamp()

    for file_path in cache_dir.glob("*.csv"):
        if older_than_days is None:
            file_path.unlink()
            deleted_count += 1
        else:
            file_age_days = (current_time - file_path.stat().st_mtime) / 86400
            if file_age_days > older_than_days:
                file_path.unlink()
                deleted_count += 1

    if deleted_count > 0:
        print(f"ğŸ—‘ï¸  ÄÃ£ xÃ³a {deleted_count} file cache")
    else:
        print("âœ… KhÃ´ng cÃ³ file cache nÃ o Ä‘á»ƒ xÃ³a")

    return deleted_count


if __name__ == "__main__":
    # Test
    df = fetch_binance_data(timeframe="1d", limit=100)
    print(df.head())
