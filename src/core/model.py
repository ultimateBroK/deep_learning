"""
üß† MODEL MODULE - X√ÇY D·ª∞NG MODEL BiLSTM
------------------------------------------

Gi·∫£i th√≠ch b·∫±ng v√≠ d·ª• ƒë·ªùi s·ªëng:
- LSTM gi·ªëng nh∆∞ "b·ªô nh·ªõ ng·∫Øn h·∫°n" - nh·ªõ th√¥ng tin quan tr·ªçng
- BiLSTM (Bidirectional) nh√¨n c·∫£ qu√° kh·ª© V√Ä t∆∞∆°ng lai
- T·∫°i sao nh√¨n t∆∞∆°ng lai ƒë∆∞·ª£c? V√¨ khi train, ta c√≥ to√†n b·ªô d·ªØ li·ªáu!

V√≠ d·ª• ƒë·ªùi s·ªëng:
- LSTM th∆∞·ªùng: "Nh√¨n b·∫£n ƒë·ªì t·ª´ ƒëi·ªÉm A ƒë·∫øn ƒëi·ªÉm B"
- BiLSTM: "Nh√¨n b·∫£n ƒë·ªì t·ª´ A ƒë·∫øn B + B ƒë·∫øn A" ‚Üí hi·ªÉu r√µ h∆°n

L·ª£i √≠ch:
- Ph√°t hi·ªán pattern t·ªët h∆°n
- Hi·ªÉu context t·ª´ 2 ph√≠a
- K·∫øt qu·∫£ th∆∞·ªùng t·ªët h∆°n LSTM th∆∞·ªùng
"""

from typing import Tuple
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models


def build_bilstm_model(
    input_shape: Tuple[int, int],
    lstm_units: list = [64, 32],
    dropout_rate: float = 0.2,
    dense_units: list = [16],
    output_units: int = 1,
    learning_rate: float = 0.001
) -> models.Sequential:
    """
    X√¢y d·ª±ng model BiLSTM

    Args:
        input_shape: Shape c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o (window_size, n_features)
        lstm_units: List s·ªë units cho m·ªói LSTM layer
        dropout_rate: T·ª∑ l·ªá dropout (ƒë·ªÉ tr√°nh overfitting)
        dense_units: List s·ªë units cho m·ªói Dense layer
        output_units: S·ªë units ·ªü output layer (th∆∞·ªùng = 1)
        learning_rate: Learning rate cho optimizer

    Returns:
        Model BiLSTM ƒë√£ ƒë∆∞·ª£c compile

    V√≠ d·ª•:
        input_shape = (60, 1)  # 60 ng√†y, 1 feature (gi√° close)
        lstm_units = [64, 32]   # 2 LSTM layers v·ªõi 64 v√† 32 units
        output_units = 1       # D·ª± ƒëo√°n 1 gi√° tr·ªã (gi√° ng√†y mai)
    """
    model = models.Sequential(name="BiLSTM_Price_Prediction")

    # Input layer
    model.add(layers.Input(shape=input_shape, name="input"))

    # BiLSTM layers
    # Layer 1: return_sequences=True ƒë·ªÉ pass cho LSTM layer ti·∫øp theo
    model.add(layers.Bidirectional(
        layers.LSTM(
            lstm_units[0],
            return_sequences=len(lstm_units) > 1,
            name="bilstm_1"
        ),
        name="bidirectional_1"
    ))
    model.add(layers.Dropout(dropout_rate, name="dropout_1"))

    # C√°c LSTM layers ti·∫øp theo (n·∫øu c√≥)
    for i, units in enumerate(lstm_units[1:], start=2):
        is_last = i == len(lstm_units)
        model.add(layers.Bidirectional(
            layers.LSTM(
                units,
                return_sequences=not is_last,
                name=f"bilstm_{i}"
            ),
            name=f"bidirectional_{i}"
        ))
        model.add(layers.Dropout(dropout_rate, name=f"dropout_{i}"))

    # Dense layers
    for i, units in enumerate(dense_units, start=1):
        model.add(layers.Dense(units, activation='relu', name=f"dense_{i}"))
        model.add(layers.Dropout(dropout_rate * 0.5, name=f"dense_dropout_{i}"))

    # Output layer
    model.add(layers.Dense(output_units, name="output"))

    # Compile model
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='mse',  # Mean Squared Error - t·ªët cho regression
        metrics=['mae']  # Mean Absolute Error - d·ªÖ hi·ªÉu h∆°n
    )

    print(f"‚úÖ ƒê√£ build model BiLSTM v·ªõi {len(lstm_units)} LSTM layers")

    return model


def print_model_summary(model: models.Sequential):
    """
    In th√¥ng tin chi ti·∫øt v·ªÅ model

    Gi·∫£i th√≠ch: Gi·ªëng nh∆∞ "th√¥ng s·ªë k·ªπ thu·∫≠t" - bi·∫øt model c√≥ bao nhi√™u layers, parameters
    """
    print("\n" + "=" * 60)
    print("üß† MODEL SUMMARY")
    print("=" * 60)
    model.summary()
    print("=" * 60)

    # ƒê·∫øm parameters
    total_params = model.count_params()
    trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])
    non_trainable_params = total_params - trainable_params

    print("\nüìä Th·ªëng k√™:")
    print(f"   Total parameters: {total_params:,}")
    print(f"   Trainable: {trainable_params:,}")
    print(f"   Non-trainable: {non_trainable_params:,}")


if __name__ == "__main__":
    # Test function
    input_shape = (60, 1)
    model = build_bilstm_model(input_shape=input_shape)
    print_model_summary(model)
